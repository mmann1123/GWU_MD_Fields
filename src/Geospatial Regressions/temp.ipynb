{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Harvest Regressions using Satellite Imagery"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import geowombat as gw\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from geowombat.ml import fit, predict, fit_predict\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error as MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Declare relevant dirs and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tif_dir = \"./data/processed/tif\"\n",
    "harvest_dir = \"./data/processed/csv/harvest\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorize and store all band TIFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = {}\n",
    "for (root, dirs, files) in os.walk(tif_dir):\n",
    "\tfor file in files:\n",
    "\t\tif (file.endswith(\".tif\")):\n",
    "\t\t\t# Determine year from file name\n",
    "\t\t\tunderscore = len(file) - file[::-1].index(\"_\")\n",
    "\t\t\tdot = len(file) - file[::-1].index(\".\") - 1\n",
    "\t\t\tyear = int(file[underscore:dot])\n",
    "\n",
    "\t\t\tif year not in years:\n",
    "\t\t\t\tyears[year] = {'file_names': [], 'band_names': []}\n",
    "\n",
    "\t\t\t# Add file and band name to year\n",
    "\t\t\tyears[year]['file_names'].append(root + \"/\" + file)\n",
    "\t\t\tyears[year]['band_names'].append(file[file.index(\"__\") + 2:len(file)\n",
    "\t\t\t\t- file[::-1].index(\"__\") - 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each year, open all bands into one stack and store it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "\tfiles = years[year]['file_names']\n",
    "\tbands = years[year]['band_names']\n",
    "\n",
    "\twith gw.open(files, stack_dim = 'band', band_names = bands) as stack:\n",
    "\t\tyears[year]['stack'] = stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in all harvest data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvest_dfs = []\n",
    "for (root, dirs, files) in os.walk(harvest_dir):\n",
    "\tfor file in files:\n",
    "\t\tif (file.endswith(\".csv\")):\n",
    "\t\t\tharvest_dfs.append(pd.read_csv(root + \"/\" + file))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all harvest data into one DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvest = pd.concat(harvest_dfs, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert DataFrame to GeoDataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geometry = gpd.points_from_xy(x = harvest.Longitude, y = harvest.Latitude)\n",
    "harvest = gpd.GeoDataFrame(harvest, crs = 'EPSG:4326', geometry = geometry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add year attribute to each row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvest['Year'] = [int(date[-4:]) for date in harvest['Date']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add harvest data to corresponding year and product category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in years:\n",
    "\tgdf = harvest[harvest['Year'] == year]\n",
    "\n",
    "\t# Remove temporary column 'Year'\n",
    "\tgdf.drop(columns = ['Year'], inplace = True)\n",
    "\n",
    "\tyears[year]['Products'] = []\n",
    "\n",
    "\tfor product in gdf['Product'].unique():\n",
    "\t\tyears[year]['Products'].append(gdf[gdf['Product'] == product])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform data extraction of the approriate stack on each year/product AOI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted = []\n",
    "for year in years:\n",
    "\t\tfor gdf in years[year]['Products']:\n",
    "\t\t\t\t# Extract\n",
    "\t\t\t\tbands = years[year]['stack'].band.values.tolist()\n",
    "\t\t\t\tgdf = gw.extract(years[year]['stack'], gdf, band_names = bands)\n",
    "\n",
    "\t\t\t\tif len(gdf.index) > 0:\n",
    "\t\t\t\t\t# Select numerical columns to be used for analysis\n",
    "\t\t\t\t\tnum = bands\n",
    "\t\t\t\t\tnum.extend(['Yld Mass(Dry)(lb/ac)'])\n",
    "\n",
    "\t\t\t\t\t# Add data to list with its metadata\n",
    "\t\t\t\t\textracted.append({'Year': year, \n",
    "\t\t\t\t\t\t'Product': gdf['Product'].values[0], 'Data': gdf[num]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a random forest object to hold the decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(criterion = \"squared_error\", \n",
    "\tbootstrap = True, oob_score = True, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_space = {'max_depth': [None, 4, 6, 8, 10, 12, 15, 20], \n",
    "\t'min_samples_leaf': [1, 2, 4, 6, 8, 10, 20, 30],\n",
    "\t'max_features': ['1.0', 'sqrt', 'log2']}\n",
    "\n",
    "\n",
    "gs = GridSearchCV(rf, param_grid = hyperparameter_space, \n",
    "    scoring = \"neg_mean_squared_error\", n_jobs = -1, cv = 5, return_train_score = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_gdf = extracted[2]['Data'].iloc[:,:-1]\n",
    "X_gdf.dropna(axis = 1, inplace = True)\n",
    "\n",
    "y_gdf = extracted[2]['Data'].iloc[:,[0,-1]]\n",
    "y_gdf.dropna(axis = 1, inplace = True)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "\t\tX_gdf, y_gdf, test_size = 0.30, random_state = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### idk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(X_train, y_train)\n",
    "\n",
    "print(\"Optimal hyperparameter combination: \", gs.best_params_)\n",
    "print(\"Mean cross-validated MSE or training score of the best_estimator: \",\n",
    "       np.sqrt(-gs.best_score_))\n",
    "\n",
    "gs.best_estimator_.fit(X_train, y_train)\n",
    "y_pred = gs.best_estimator_.predict(X_test)\n",
    "\n",
    "print(\"Test score: \", np.round(np.sqrt(MSE(y_test, y_pred)), 2))\n",
    "\n",
    "print(r2_score(y_test, gs.predict(X_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
